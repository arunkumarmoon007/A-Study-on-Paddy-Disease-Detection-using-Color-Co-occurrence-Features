import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from sklearn.metrics import confusion_matrix

import DataProcessing as load

from tensorflow.examples.tutorials.mnist import input_data

#data = input_data.read_data_sets("data/MNIST/", one_hot=True)

#print("Size of:")
#print("- Training-set:\t\t{}".format(len(data.train.labels)))
#print("- Test-set:\t\t{}".format(len(data.test.labels)))
#print("- Validation-set:\t{}".format(len(data.validation.labels)))

#data.test.labels[0:5, :]
#data.test.cls = np.array([label.argmax() for label in data.test.labels])




train_set_x_orig = load.train_set_x_orig
test_set_x_orig =  load.test_set_x_orig
train_set_y = load.train_set_y
test_set_y = load.test_set_y
print(test_set_y.shape)


### START CODE HERE ### (˜ 3 lines of code)
m_train = len(train_set_y)
m_test = len(test_set_y)
num_px = 64
### END CODE HERE ###


### START CODE HERE ### (˜ 2 lines of code)
train_set_x_flatten = load.Train_Matrix
test_set_x_flatten = load.Test_Matrix
### END CODE HERE ###


print(train_set_x_flatten.shape)
print(test_set_x_flatten.shape)

val = 0.0
for i in range(train_set_x_flatten.shape[0]):
    for j in range(train_set_x_flatten.shape[1]):
        val = max(val,train_set_x_flatten[i][j])
for i in range(test_set_x_flatten.shape[0]):
    for j in range(test_set_x_flatten.shape[1]):
        val = max(val,test_set_x_flatten[i][j])
print(val)
train_set_x = train_set_x_flatten/val
test_set_x = test_set_x_flatten/val



##############
One_hot_matrix_train = np.zeros(shape=(len(train_set_y),3))
One_hot_matrix_test  = np.zeros(shape=(len(test_set_y),3))
print(One_hot_matrix_train.shape)
for i in range(len(train_set_y)):
    One_hot_matrix_train[i][ train_set_y[i] ] = 1
for i in range( len(test_set_y) ):
    One_hot_matrix_test[i][ test_set_y ] = 1
##############

#data.test.cls[0:5]
# We know that MNIST images are 28 pixels in each dimension.
#img_size = 28

# Images are stored in one-dimensional arrays of this length.
#img_size_flat = img_size * img_size
##########
img_size_flat = load.Number_of_features
print(img_size_flat)
num_classes = 3
##########

# Number of classes, one class for each of 10 digits.
#num_classes = 10


x = tf.placeholder(tf.float32, [None, img_size_flat])
y_true = tf.placeholder(tf.float32, [None, num_classes])
y_true_cls = tf.placeholder(tf.int64, [None])
weights = tf.Variable(tf.zeros([img_size_flat, num_classes]))
biases = tf.Variable(tf.zeros([num_classes]))
logits = tf.matmul(x, weights) + biases
y_pred = tf.nn.softmax(logits)
y_pred_cls = tf.argmax(y_pred, axis=1)
cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y_true)
cost = tf.reduce_mean(cross_entropy)
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)
correct_prediction = tf.equal(y_pred_cls, y_true_cls)
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
session = tf.Session()
session.run(tf.global_variables_initializer())
batch_size = 10


def optimize(num_iterations):
    for i in range(num_iterations):
        # Get a batch of training examples.
        # x_batch now holds a batch of images and
        # y_true_batch are the true labels for those images.
        #x_batch, y_true_batch = data.train.next_batch(batch_size)
        #print("Found")
        #print(x_batch.shape)
        #print(y_true_batch.shape)
        #print(x_batch[0][345])
        #print(y_true_batch[0])

        #### x_batch contains features of a image in a row
        #### y_true_batch containg one hot encoding

        ###########
        x_batch = train_set_x.transpose()
        y_true_batch = One_hot_matrix_train
        ###########

        # Put the batch into a dict with the proper names
        # for placeholder variables in the TensorFlow graph.
        # Note that the placeholder for y_true_cls is not set
        # because it is not used during training.
        feed_dict_train = {x: x_batch,
                           y_true: y_true_batch}

        # Run the optimizer using this batch of training data.
        # TensorFlow assigns the variables in feed_dict_train
        # to the placeholder variables and then runs the optimizer.
        session.run(optimizer, feed_dict=feed_dict_train)

#print(data.test.images.shape)
#print(data.test.labels.shape)
#print(data.test.cls.shape)

#for i in range (10):
#    print(data.test.labels[i])
#for i in range (10):
#    print(data.test.cls[i])

##################
feed_dict_test = {x: test_set_x.transpose(),       # 10000 * 784
                  y_true: One_hot_matrix_test,  # 10000 * 10
                  y_true_cls: test_set_y} # 10000 ,
##################

#feed_dict_test = {x: data.test.images,       # 10000 * 784
#                  y_true: data.test.labels,  # 10000 * 10
#                  y_true_cls: data.test.cls} # 10000 ,


def print_accuracy():
    # Use TensorFlow to compute the accuracy.
    acc = session.run(accuracy, feed_dict=feed_dict_test)

    # Print the accuracy.
    print("Accuracy on test-set: {0:.1%}".format(acc))


print_accuracy()
optimize(num_iterations=1)
print_accuracy()
optimize(num_iterations=2)
print_accuracy()
optimize(num_iterations=3)
print_accuracy()
optimize(num_iterations=4)
print_accuracy()
optimize(num_iterations=5)
print_accuracy()
optimize(num_iterations=10)
print_accuracy()
optimize(num_iterations=100)
print_accuracy()


#optimize(num_iterations=9)
#print_accuracy()

#optimize(num_iterations=990)
#print_accuracy()

#plot_example_errors()
#plot_weights()
#print_confusion_matrix()
